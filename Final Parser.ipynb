{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7e916f",
   "metadata": {},
   "source": [
    "# Install Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9789c",
   "metadata": {},
   "source": [
    "# Download 'en_core_web_sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86677b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (61.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sana jalgaonkar\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.3.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7621ef07",
   "metadata": {},
   "source": [
    "# Importing libraries & packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93b4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ef3d4",
   "metadata": {},
   "source": [
    "# Function to read resumes from the folder one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f9dcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath='C:/Users/SANA JALGAONKAR/Desktop/Resume Parsing/Samples' #enter your path here where you saved the resumes\n",
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "\n",
    "def pdfextract(file):\n",
    "    fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "    countpage = fileReader.getNumPages()\n",
    "    count = 0\n",
    "    text = []\n",
    "    while count < countpage:    \n",
    "        pageObj = fileReader.getPage(count)\n",
    "        count +=1\n",
    "        t = pageObj.extractText()\n",
    "        print (t)\n",
    "        text.append(t)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895ebec",
   "metadata": {},
   "source": [
    "# Function that does phrase matching and builds a candidate profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d0d263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_profile(file):\n",
    "    text = pdfextract(file) \n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    #below is the csv where we have all the keywords transfered into data frame, you can customize your own\n",
    "    keyword_dict = pd.read_csv('\"C:/Users/SANA JALGAONKAR/Desktop/Resume Parsing/Skills.csv\"')\n",
    "    #stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    #NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    #R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
    "\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    #matcher.add('Stats', None, *stats_words)\n",
    "    #matcher.add('NLP', None, *NLP_words)\n",
    "    matcher.add('ML', None, *ML_words)\n",
    "    matcher.add('DL', None, *DL_words)\n",
    "    #matcher.add('R', None, *R_words)\n",
    "    matcher.add('Python', None, *python_words)\n",
    "    matcher.add('DE', None, *Data_Engineering_words)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []  \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "        span = doc[start : end]  # get the matched slice of the doc\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    \n",
    "    ## convertimg string of keywords to dataframe\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    \n",
    "    base = os.path.basename(file)\n",
    "    filename = os.path.splitext(base)[0]\n",
    "       \n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "\n",
    "    return(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3eb00e",
   "metadata": {},
   "source": [
    "# Code to execute/call the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3766da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sana Jalgaonkar\n",
      " \n",
      " Email: jalgaonkarsana28@gmail.com\n",
      " \n",
      " LinkedIn:\n",
      " \n",
      " sana-jalgaonkar28\n",
      " \n",
      " Github:\n",
      " \n",
      " Sana Jalgaonkar\n",
      " \n",
      " Medium:\n",
      " \n",
      " sanajalgaonkar2810-sj\n",
      " \n",
      " Phone: +91-8956574654\n",
      " \n",
      " EDUCATIONAL QUALIFICATION\n",
      " \n",
      " Bachelor’s in Computer Science(BCS) |\n",
      " \n",
      " 2015-18\n",
      " \n",
      " Abeda Inamdar Senior College, Pune-65%\n",
      " \n",
      " HSC| Maharashtra State Board| 2013-15\n",
      " \n",
      " Janata Vidyalaya Jr.College, Khopoli-65%\n",
      " \n",
      " SSC| Maharashtra State Board| 2013\n",
      " \n",
      " Carmel Convent School, Khopoli-75%\n",
      " \n",
      " TRAININGS & CERTIFICATES\n",
      " \n",
      " Learning Path in Data Science |  Data Analyst |\n",
      " \n",
      " 2020-21\n",
      " \n",
      " Board Inﬁnity\n",
      " \n",
      " Full Stack Java Development |  Java Developer|\n",
      " \n",
      " 2018-19\n",
      " \n",
      " SEED Infotech\n",
      " \n",
      " TECHNICAL SKILLS\n",
      " \n",
      " -\n",
      " \n",
      " Data Analytics\n",
      " \n",
      " -\n",
      " \n",
      " Web Scraping\n",
      " \n",
      " -\n",
      " \n",
      " Data Visualization( Tableau,Excel,Power BI)\n",
      " \n",
      " -\n",
      " \n",
      " Python\n",
      " \n",
      " -\n",
      " \n",
      " Machine Learning\n",
      " \n",
      " -\n",
      " \n",
      " SQL\n",
      " \n",
      " -\n",
      " \n",
      " Maths and Statistics\n",
      " \n",
      " SKILLS & ABILITIES\n",
      " \n",
      " -\n",
      " \n",
      " Disciplined and Organized\n",
      " \n",
      " -\n",
      " \n",
      " Time Management\n",
      " \n",
      " -\n",
      " \n",
      " Adaptive and Punctual\n",
      " \n",
      " -\n",
      " \n",
      " Communication Skills\n",
      " \n",
      " -\n",
      " \n",
      " Quick Learner\n",
      " \n",
      " INTEREST & HOBBIES\n",
      " \n",
      " -\n",
      " \n",
      " Drawing\n",
      " \n",
      " -\n",
      " \n",
      " Reading\n",
      " \n",
      "\n",
      " WORK EXPERIENCE\n",
      " \n",
      " Data analytics virtual experience participant\n",
      " \n",
      " ,\n",
      " \n",
      " KPMG\n",
      " \n",
      " -\n",
      " \n",
      " Tools Used- MS Excel\n",
      " \n",
      " -\n",
      " \n",
      " Analyzed three datasets provided by SPROCKET CENTRAL- a\n",
      " \n",
      " client company of KPMG to reveal useful customer insights which\n",
      " \n",
      " could improve performance by focusing on high value customers.\n",
      " \n",
      " PROJECTS\n",
      " \n",
      " Customer segmentation for Ecommerce Dataset\n",
      " \n",
      " -\n",
      " \n",
      " Tools Used-\n",
      " \n",
      " Python, Machine Learning(K-Means) and RFM\n",
      " \n",
      " -\n",
      " \n",
      " Process Followed-\n",
      " \n",
      " -\n",
      " \n",
      " Performed EDA\n",
      " \n",
      " -\n",
      " \n",
      " Handled the missing values and treated the categorical values.\n",
      " \n",
      " -\n",
      " \n",
      " Plotted the elbow plot to know the exact number of clusters and\n",
      " \n",
      " Used K-means Algorithm for clustering  on RFM values.\n",
      " \n",
      " -\n",
      " \n",
      " Along with the segmentation of customers a table with marketing\n",
      " \n",
      " strategies was made.\n",
      " \n",
      " Bank marketing prediction\n",
      " \n",
      " -\n",
      " \n",
      " Tools Used-\n",
      " \n",
      " Python, Machine Learning(Logistic Regression ,\n",
      " \n",
      " Random Forest)\n",
      " \n",
      " -\n",
      " \n",
      " Handled the missing values and treated the categorical values.\n",
      " \n",
      " -\n",
      " \n",
      " Performed bi-variate analysis to identify the features that were\n",
      " \n",
      " directly associated with the target variable\n",
      " \n",
      " -\n",
      " \n",
      " Trained the test split on two models-Logistic Regression and\n",
      " \n",
      " Random Forest.\n",
      " \n",
      " Data visualization of foreign direct investment\n",
      " \n",
      " -\n",
      " \n",
      " Tool Used-\n",
      " \n",
      " Tableau\n",
      " \n",
      " -\n",
      " \n",
      " Cleaned the data and performed EDA\n",
      " \n",
      " -\n",
      " \n",
      " Created a dashboard designed with various visualization graphs,\n",
      " \n",
      " as a solution for the problem statements.\n",
      " \n",
      " DECLARATION\n",
      " \n",
      " I hereby declare that the above provided information is\n",
      " \n",
      " correct and true to the best of my knowledge.\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '\"C:/Users/SANA JALGAONKAR/Desktop/Resume Parsing/Skills.csv\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m file \u001b[38;5;241m=\u001b[39m onlyfiles[i]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#dat = create_profile(file)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m final_database \u001b[38;5;241m=\u001b[39m final_database\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcreate_profile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_database)\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mcreate_profile\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#below is the csv where we have all the keywords transfered into data frame, you can customize your own\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m keyword_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/SANA JALGAONKAR/Desktop/Resume Parsing/Skills.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m ML_words \u001b[38;5;241m=\u001b[39m [nlp(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m keyword_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMachine Learning\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '\"C:/Users/SANA JALGAONKAR/Desktop/Resume Parsing/Skills.csv\"'"
     ]
    }
   ],
   "source": [
    "final_database=pd.DataFrame()\n",
    "i = 0 \n",
    "while i < len(onlyfiles):\n",
    "    file = onlyfiles[i]\n",
    "    #dat = create_profile(file)\n",
    "    final_database = final_database.append(create_profile(file))\n",
    "    i +=1\n",
    "    print(final_database)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc5c20cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec797dc6",
   "metadata": {},
   "source": [
    "# Code to count words under each category and visulaize it through Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324c034c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Keyword'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Keyword'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_database2 \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_database\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKeyword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([final_database[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCandidate Name\u001b[39m\u001b[38;5;124m'\u001b[39m], final_database[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubject\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39munstack()\n\u001b[0;32m      2\u001b[0m final_database2\u001b[38;5;241m.\u001b[39mreset_index(inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m final_database2\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Keyword'"
     ]
    }
   ],
   "source": [
    "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "final_database2.reset_index(inplace = True)\n",
    "final_database2.fillna(0,inplace=True)\n",
    "new_data = final_database2.iloc[:,1:]\n",
    "new_data.index = final_database2['Candidate Name']\n",
    "#execute the below line if you want to see the candidate profile in a csv format\n",
    "result=new_data.to_csv('Extracted_result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe3b9d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m})\n\u001b[1;32m----> 3\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[43mnew_data\u001b[49m\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbarh(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResume keywords by category\u001b[39m\u001b[38;5;124m\"\u001b[39m, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m7\u001b[39m), stacked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m new_data\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_data' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(25,7), stacked=True)\n",
    "labels = []\n",
    "for j in new_data.columns:\n",
    "    for i in new_data.index:\n",
    "        label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "        labels.append(label)\n",
    "patches = ax.patches\n",
    "for label, rect in zip(labels, patches):\n",
    "    width = rect.get_width()\n",
    "    if width > 0:\n",
    "        x = rect.get_x()\n",
    "        y = rect.get_y()\n",
    "        height = rect.get_height()\n",
    "        ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39d4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
